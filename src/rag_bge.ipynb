{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from typing import List, Dict\n",
    "import numpy as np\n",
    "from llama_index.core import Document, VectorStoreIndex, Settings\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.retrievers import QueryFusionRetriever\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.core.schema import TextNode\n",
    "from llama_index.core import StorageContext, VectorStoreIndex\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "import faiss\n",
    "\n",
    "\n",
    "\n",
    "HF_TOKEN = \"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\"\n",
    "os.environ[\"HUGGINGFACE_HUB_TOKEN\"] = HF_TOKEN \n",
    "login(token=HF_TOKEN)\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wiki data load\n",
    "with open('/data/ephemeral/home/data/wikipedia_documents.json') as f:\n",
    "    wiki_data = json.load(f)\n",
    "id_to_title = {v[\"document_id\"]: v[\"title\"] for v in wiki_data.values()}\n",
    "\n",
    "\n",
    "train_set_dir = \"/data/ephemeral/home/data/train_dataset/\"\n",
    "dataset = load_from_disk(train_set_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복문서 제거\n",
    "# chunk size\n",
    "# overlap size\n",
    "# 모델 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 모델 로드 설정 ---\n",
    "GEMMA_MODEL_NAME = \"google/gemma-3-4b-it\"  # 메모리 효율성을 위해 4b 대신 9b를 예시로 사용 (사용자 환경에 따라 변경 가능)\n",
    "EMBEDDING_MODEL_NAME = \"BAAI/bge-m3\" # jina-embeddings-v4\n",
    "RERANKER_MODEL_NAME = \"BAAI/bge-reranker-v2-m3\" # jina-reranker-v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LLM 및 Tokenizer 로드 ---\n",
    "def load_gemma():\n",
    "    \"\"\"Gemma 모델과 토크나이저를 로드합니다.\"\"\"\n",
    "    # Q: Gemma 3-4b-it 사용 예정이었는데, 현재는 Gemma 2-9b-it을 사용하려 합니다.\n",
    "    # A: VRAM 상황에 따라 모델 이름을 적절히 변경하여 사용하세요.\n",
    "    tokenizer = AutoTokenizer.from_pretrained(GEMMA_MODEL_NAME)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        GEMMA_MODEL_NAME,\n",
    "        device_map=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "    )\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents: List[Document] = []\n",
    "for doc_id, data in wiki_data.items():\n",
    "    # 'text' 필드를 문서 내용으로 사용\n",
    "    data['text'] = data['text'].replace('\\\\n', '\\n')\n",
    "    \n",
    "    documents.append(\n",
    "        Document(\n",
    "            text=data['text'],\n",
    "            metadata={\n",
    "                \"document_id\": data['document_id'],\n",
    "                \"title\": data['title'],\n",
    "                \"corpus_source\": data['corpus_source']\n",
    "            }\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| model | chunk | overlap |\n",
    "|-------|-------|---------|\n",
    "| BGE   | 256   | 50     |\n",
    "| BGE   | 256   | 100     |\n",
    "| BGE   | 512   | 50     |\n",
    "| BGE   | 512   | 100     |\n",
    "| jina  | 256   | 50     |\n",
    "| jina  | 256   | 100     |\n",
    "| jina  | 512   | 50     |\n",
    "| jina  | 512   | 100     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 문서 개수: 60613개\n",
      "생성된 청크(Node) 개수: 128488개\n",
      "첫 번째 청크 텍스트 예시: 이 문서는 나라 목록이며, 전 세계 206개 나라의 각 현황과 주권 승인 정보를 개요 형태로 나열하고 있다.\n",
      "\n",
      "이 목록은 명료화를 위해 두 부분으로 나뉘어 있다.\n",
      "\n",
      "# 첫 번째 부...\n"
     ]
    }
   ],
   "source": [
    "# 3. 문서 청킹 (Node 생성)\n",
    "# SentenceSplitter는 문장 단위 분할을 기본으로 하면서, \n",
    "# 최종 청크 크기를 chunk_size=512로 제한합니다.\n",
    "splitter = SentenceSplitter(chunk_size=512, chunk_overlap=50) # origin 50\n",
    "\n",
    "# nodes에는 작은 텍스트 청크(TextNode)들이 리스트 형태로 담깁니다.\n",
    "nodes: List[TextNode] = splitter.get_nodes_from_documents(documents)\n",
    "\n",
    "print(f\"원본 문서 개수: {len(documents)}개\")\n",
    "print(f\"생성된 청크(Node) 개수: {len(nodes)}개\")\n",
    "print(f\"첫 번째 청크 텍스트 예시: {nodes[0].get_content()[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = HuggingFaceEmbedding(\n",
    "    model_name=EMBEDDING_MODEL_NAME,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "# vector_index = VectorStoreIndex(nodes, embed_model=embed_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- VectorStoreIndex 생성 시작 (임베딩 중) ---\n"
     ]
    }
   ],
   "source": [
    "# faiss vs\n",
    "print(\"--- VectorStoreIndex 생성 시작 (임베딩 중) ---\")\n",
    "\n",
    "dummy_emb = embed_model.get_text_embedding(\"dim 체크용\")\n",
    "dim = len(dummy_emb)\n",
    "faiss_index = faiss.IndexFlatIP(dim) \n",
    "vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index = VectorStoreIndex(\n",
    "    nodes,\n",
    "    storage_context=storage_context,\n",
    "    embed_model=embed_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Reranker (사용자 정의) ---\n",
    "from sentence_transformers import CrossEncoder \n",
    "\n",
    "class Reranker:\n",
    "    def __init__(self, model_name: str = RERANKER_MODEL_NAME):\n",
    "        self.model = CrossEncoder(model_name, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def rerank(self, query: str, docs: List[Dict], doc_id, top_k: int = 5) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        query와 docs[{'text': ..., ...}]를 받아, score 기준으로 다시 정렬해서 top_k만 반환합니다.\n",
    "        \"\"\"\n",
    "        if not docs:\n",
    "            return []\n",
    "\n",
    "        pairs = [[query, d] for d in docs]\n",
    "        scores = self.model.predict(pairs)  # shape (len(docs),)\n",
    "        scored_docs = list(zip(docs, scores))\n",
    "        scored_id = list(zip(doc_id, scores)) \n",
    "\n",
    "        scored_docs.sort(key=lambda x: x[1], reverse=True)\n",
    "        scored_id.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        return scored_docs[:top_k], scored_id[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reranker = Reranker()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer, model = load_gemma()\n",
    "# gemma_llm = HuggingFaceLLM(\n",
    "#     # model_name을 지정할 필요가 없거나, 명시적으로 지정해도 model/tokenizer 인자가 우선됩니다.\n",
    "#     model=model,        # 이미 로드된 PyTorch 모델 객체\n",
    "#     tokenizer=tokenizer,  # 이미 로드된 Tokenizer 객체\n",
    "#     device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "#     # device_map=\"auto\" 등은 이미 model 로드 시 적용되었으므로 LlamaIndex LLM에서는 불필요\n",
    "    \n",
    "#     # 템플릿 처리 방식 등 LlamaIndex 관련 설정만 추가\n",
    "#     context_window=8192, # 예시: Gemma의 Context Window 설정 (필요에 따라)\n",
    "# )\n",
    "\n",
    "# # 3. LlamaIndex 설정에 적용\n",
    "# Settings.llm = gemma_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#골든리트리버\n",
    "retriever = vector_index.as_retriever(similarity_top_k=50)\n",
    "\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_defaults(nodes=nodes, similarity_top_k=50)\n",
    "\n",
    "# dense -> 의미  , bm25 -> 언어적 \n",
    "# 미국 상원 query \n",
    "# kiwi 형태소 + den rag\n",
    "# ㄴ \n",
    "#\n",
    "\n",
    "\n",
    "# fusion_retriever = QueryFusionRetriever(\n",
    "#     retrievers=[retriever, bm25_retriever],\n",
    "#     similarity_top_k=30,  \n",
    "#     num_queries=1,\n",
    "#     use_async=False,mode=\"reciprocal_rerank\"\n",
    "# )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = dataset['train'][12]['question']\n",
    "retrieved_nodes = retriever.retrieve(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_for_rerank = [n.node.text for n in retrieved_nodes]\n",
    "ids_for_rerank = [n.node.metadata['document_id'] for n in retrieved_nodes]\n",
    "\n",
    "reranked_results = reranker.rerank(query, docs_for_rerank, ids_for_rerank, top_k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19310, 19312, 12253, 5043, 489]\n"
     ]
    }
   ],
   "source": [
    "result = list(dict.fromkeys((list(map(int, ((list(np.array(reranked_results[1])[:,0].astype(int)))))))))[:5]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19310., 19310., 19310., 19312., 12253.])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(reranked_results[1])[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('동앵글인들은 초기에는, 분명하게 우파 왕의 이름을 따서 이름지어진 우핑가스 왕조 (비록 우파의 이름이 \"늑대의 후손들\"을 뜻하는 왕조의 이름에서 유래한 후대 때 만들어진 것으로 보이긴 하지)의 지배를 받았으며, 이 왕조는 전통 신앙을 따르는 자들이었다. 이스트앵글리아 왕국의 초기 역사와 이들의 지도자들에 대한 필수불가결한 자료가 비드의 『교회사』이기는 하지만, 비드는 이스트앵글리아 왕국의 왕들의 연대기나 이들의 재위 시기에 대해선 전하지는 않았다. 이스트앵글리아 왕국의 권력의 중심이 서퍽주의 동부인 스네이프와 서튼후에 있는 배무덤 집결지라는 점을 제외하면, 초기 왕들이나, 왕국이 어떻게 조직되었는지에 대해선 알려진 것이 없다. 노스퍽과 사우스퍽은 초기 동앵글리아 왕들이 도착하기 전에 있었을 수도 있다.',\n",
       "  np.float32(0.98431545)),\n",
       " ('노스퍽과 사우스퍽은 초기 동앵글리아 왕들이 도착하기 전에 있었을 수도 있다. \\n\\n『교회사』에 따르면, 우핑가스 왕조의 왕 중 가장 강력했던 이는 \"우파를 아버지로 두었던 티틸의 아들\" 래드왈드였다고 한다 7세기 초 짧은 기간에, 래드왈드의 통치를 받던 이스트앵글리아는 앵글로색슨 잉글랜드의 왕국들 중에서 가장 강력했으며, 비드는 그를 험버강 이남에 있는 왕국들의 대군주로 묘사했다. 616년에, 그는 노섬브리아의 왕 애설프리트를 리버이들 전투에서 패배시켜 전사시키고 노섬브리아의 에드윈을 왕위에 앉힐 만큼 강력했다. 그는 서튼후에 있는 사치스러운 배무덤으로써, 개인적인 영예를 누렸던 것으로 보인다. 우핑가스 왕조가 동부 스웨덴의 왕족들의 후예일지도 모른다며, 서튼후에 있는 봉분 1호에서 발견된 유물과 스웨덴의 벤델에서 발견된 유물들 간의 공통점의 정도를 증거로, 블레어가 의혹을 제기했었다.',\n",
       "  np.float32(0.61625445)),\n",
       " ('그러나, 이전엔 스웨덴에서 왔다고 여겨졌던 유물들은 현재 잉글랜드에서 만들어진 것으로 보며, 우핑가스 왕조가 스웨덴을 기원으로 했다는 것도 가능성이 낮아 보인다.',\n",
       "  np.float32(0.5249947)),\n",
       " ('마지막 우핑가스 왕조 출신 왕은 앨프왈드로, 749년에 사망했다.  7세기 말과 8세기 동안 이스트앵글리아는 계속해서 머시아의 패권이라는 그림자에 가려져 있었다가, 794년에 머시아의 오파는 이스트앵글리아의 왕 애설버트를 처형한 뒤에 이스트앵글리아의 지배권을 장악했다.  796년에 오파가 죽은 뒤에, 에와드왈드 기간 동앵글리아의 일시적인 부활은 새로운 머시아의 왕 코엔울프에게 진압되었다. \\n\\n이스트앵글리아의 독립은 825년에 애설스턴이 이끈 반머시아 반란으로 되찾았다. 머시아의 지배력을 회복하려는 머시아의 베오른울프의 시도는 베오른울프의 패배와 전사로 이어졌고, 그의 후임자 루데카도 827년에 같은 상황을 맞이했다. 이스트앵글리아인들은 웨식스의 에그버트에게 머시아의 위협으로부터 보호를 요청했고, 애설스턴은 에그버트사 자신의 대군주임을 받아들였다.',\n",
       "  np.float32(0.07164709)),\n",
       " ('유연(c=柔然|p=Róurán)은 4세기 말부터 6세기 말까지 동아시아 북쪽의 넓은 지역을 통치하던 민족이다. 5세기부터 6세기에 걸쳐 몽골고원에서 황인종이 건국한 국가의 이름을 한자로 차음(借音)한 것이다. 연연(蠕蠕), 여여(茹茹), 예예(芮芮) 등으로도 표기된다. 몽골 고원부터 천산산맥 근처의 철륵(카자흐족, 키르기스족)까지 영향력이 닿았다. 수나라 서북 지역의 핑량에서 이주한 아사나씨阿史那에 의해 무너졌다. 그러나 이후 아사나씨의 괵튀르크는 유연에 속해 있던 천산산맥 근처의 철륵(카자흐족, 키르기스족)을 점령하렸으나 다시 정령에 의해 멸망했다.',\n",
       "  np.float32(0.0044530826))]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reranked_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': '이스트앵글리아 왕국',\n",
       " 'context': '웨하가 동앵글리아의 초대 왕으로 기록되고, 그 뒤를 우파가 뒤를 잇던, 동앵글리아 왕국은 6세기 초에 형성되었다\\\\n\\\\n749년까지 이스트앵글리아의 왕들은 반신화적인 인물인 우파의 이름을 딴 우핑가스 왕조 출신들이었다. 이스트앵글리아의 래드왈드의 재위 당시인 7세기 초에, 앵글로색슨 왕국들은 평화로운 상태였다. 기독교 신자로 세례를 받은 첫 이스트앵글리아의 왕인 래드왈드는 우드브리지 인근 서튼후에서 배무덤 양식으로 묻힌 인물이라고 많은 학자들에게 여겨진다. 대략 624년경에 그가 사망하고나서 수십 년 동안에, 동앵글리아는 머시아 왕국의 서서히 지배를 받게 되었다. 래드왈드의 후임자들 몇몇은 전투 중에 사망했으며, 이중에는 기독교를 완전히 정착시킨 부르군트의 펠릭스 주교의 지도와 함께, 나라를 다스렸던 시게버트 (641년 전사)가 있었다.\\\\n\\\\n794년에 애설버트 2세가 머시아인들에게 사망하고부터 825년까지, 이스트앵글리아 왕국은 796년에 애드왈드의 잠깐의 시기를 제외하고는 독립 왕국으로서 기능을 상실했었다. 바이킹들이 전투에서 이스트앵글리아군과 전투 중에 전사한 순교왕 에드먼드를 패배시킨 869년까지 왕국은 남아있었다. 879년 이후 바이킹들은 이스트앵글리아에 영구적으로 정착했다. 903년에 추방당한 애슬링의 애설울드가 이스트앵글리아의 데인인들에게 자신의 조카인 대 애드워드에게 전쟁을 일으키게끔 부추겼다. 데인족들의 계속된 패배가 이어진 후인 917년경에 이스트앵글리아는 에드워드에게 복속되었고 잉글랜드 왕국으로 통합되었으며, 이후 백작령이 되었다.',\n",
       " 'question': '우핑가스 왕조의 이름은 어디서 유래하였나?',\n",
       " 'id': 'mrc-0-000425',\n",
       " 'answers': {'answer_start': [86], 'text': ['반신화적인 인물인 우파']},\n",
       " 'document_id': 19308,\n",
       " '__index_level_0__': 286}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q. 카드모스의 부하들이 간 곳에는 무엇이 있었는가?\n",
      "[37482. 37482. 20734. 45765. 60518. 19191. 24376. 59523. 60517. 45927.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_context = \"\\n\\n---\\n\\n\".join([f\"[{i+1}] {d[0]}\" for i, d in enumerate(reranked_results[0])])\n",
    "print(f'Q. {query}')\n",
    "\n",
    "print(np.array(reranked_results[1])[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': '메이레키 대화재',\n",
       " 'context': '옛날 에도에서는 17세 소녀인 우메노(梅乃)가 살고 있었다. 부유한 전당포 가문의 외동딸이었던 우메노는 에도에서 열린 마츠리에 나서던 도중에 잘 생긴 소년의 모습에 반하게 된다. 소년의 모습을 다시 보고 싶었던 우메노는 부모에게 시집을 가고 싶다고 말했지만 부모의 반대로 인해 좌절했고 음력 1월 18일에 상사병으로 인해 사망하고 만다.\\\\n\\\\n우메노의 부모는 딸의 결혼에 반대한 것을 크게 후회하면서 슬픔에 빠지게 된다. 며칠 뒤 에도의 큰 사찰인 혼묘지(本妙寺)에서는 우메노의 장례식이 열렸다. 일본의 장례식에서는 죽은 사람이 생전에 아끼던 옷을 관에 덮어주는 풍습이 있었다. 우메노의 어머니는 우메노가 마츠리에 나서던 도중에 입었던 붉은색 후리소데를 덮어주었다.\\\\n\\\\n어느 날 혼묘지에서 일하던 일꾼들이 우메노의 후리소데를 몰래 빼돌려서 시장에 팔았다. 그렇지만 3년 동안 우메노가 입었던 후리소데를 입은 3명의 소녀들이 매년 음력 1월 18일에 원인을 알 수 없는 질병으로 인해 사망하고 만다. 혼묘지에서 열린 소녀들의 장례식에서 돌아온 우메노의 후리소데를 알고 있던 일꾼들은 죄책감과 불길함에 시달리면서 이 사실을 스님에게 고백하게 된다. 스님은 우메노의 부모에게 우메노의 한과 저주가 서린 후리소데를 불에 태워 없애기로 결정했다.\\\\n\\\\n혼묘지의 스님은 뜰에 불을 피우는 동안에 불교의 경전을 외우면서 우메노의 후리소데를 불에 던져버린다. 그런데 불에 타고 있던 우메노의 후리소데가 예상치 못한 돌풍에 날아가면서 혼묘지의 본당의 지붕에 날아앉았다. 우메노의 후리소데에서 시작된 불은 혼묘지의 본당과 사찰 전체를 불태웠다. 당시 에도는 음력 11월부터 3개월 동안 비가 내리지 않아 건조한 상태였고 강한 북풍이 불면서 불은 삽시간에 에도 전체로 확산되었다.',\n",
       " 'question': '우메노의 사인은?',\n",
       " 'id': 'mrc-1-000379',\n",
       " 'answers': {'answer_start': [171], 'text': ['상사병']},\n",
       " 'document_id': 11945,\n",
       " '__index_level_0__': 242}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][86]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 델포이의 신탁에 따라 암소를 따라간 카드모스는 테베 땅에 이르렀다. 카드모스는 암소를 잡아서 신들에게 공양하려고 부하들에게 근처의 샘으로 물심부름을 보냈다. 샘은 드래곤이 지키고 있었고, 드래곤은 카드모스의 부하 여럿을 죽인 뒤 카드모스의 칼에 죽었다.\n",
      "\n",
      "《비블리오테카》에 따르면 이 드래곤은 아레스의 신수였다고 한다. 아테나는 드래곤의 이빨 중 절반을 카드모스에게 주고 그것을 땅에 심으라고 했다. 카드모스가 그렇게 하자 고랑마다 사나운 무장한 사내들이 튀어나왔다. 그들에게 겁을 먹은 카드모스는 그들 사이에 돌을 집어던졌고, 돌을 누가 던졌냐고 시비가 붙은 용아병들은 서로 싸우다가 다섯 명만 남기고 나머지는 모두 죽었다.\n",
      "\n",
      "---\n",
      "\n",
      "[2] 살아남은 용아병 다섯은 에키온, 우다에오스, 크토노니오스, 퓌헤레노르, 펠로루스이며, 이 다섯은 카드모스를 도와 테베라는 도시를 건립했다. 카드모스는 드래곤을 죽인 대가로 8년동안 아레스의 노예로 살았고, 그 기간이 끝나자 아레스와 아프로디테의 딸인 하르모니아를 아내로 맞았다. \n",
      "\n",
      "한편, 미틸레네의 헬라니코스의 판본에 따르면 애초부터 용아병은 다섯 명이 튀어나왔으며, 아레스가 카드모스를 죽이려고 하는 것을 제우스가 나서서 살려 주었다. 용아병들 중 에키온은 뒤에 카드모스의 딸 아가베와 결혼했고, 둘 사이에 태어난 아들 펜테우스가 카드모스의 뒤를 이어 테베의 왕이 되었다.\n",
      "\n",
      "---\n",
      "\n",
      "[3] 테베의 왕 카드무스는 고령으로 인해 그의 외손 펜테우스에게 양위하였다. 카드무스의 아들인 폴리도로스의 뒤를 이었다는 설도 있다.\n",
      "\n",
      "펜테우스는 이모 세멜레의 아들이기도 한 디오니소스 신의 숭배를 포기하였고, 이모들에게는 의식에 참여하지 못하게 했다. 이에 화가 난 디오니소스는 펜테우스의 어머니인 아가베와 이모인 이노, 그리고 아우토노에 그리고 모든 테베의 여인과 함께 술에 취해 키타에론 산으로 달려가게 하였다. 펜테우스는 디오니소스를 가두었지만, 디오니소스는 신이었기에 결박은 무너지고 옥문은 그를 위해 열렸다.\n",
      "\n",
      "디오니소스는 그 후 펜테우스를 유혹하여 음주 의식을 정찰하게 하였다. 카드무스의 딸들은 나무 위에 있는 그를 발견하고 야생동물로 생각하였다. 펜테우스는 끌려내려와 고문당하고 테베에서 추방되었다.\n",
      "\n",
      "---\n",
      "\n",
      "[4] 그 후, 크라테로스와 안티파트로스는 군대를 양분하여 크라테로스는 소아시아에서 에우메네스와 전투를 벌였고, 안티파트로스는 이집트를 지원하기 위해 킬리키아로 향했다.\n",
      "\n",
      "그리고 크라테로스와 네오프톨레모스는 에우메네스와 소아시아 북서부의 헬레스폰투스 근교에서 싸웠다. (헬레스폰투스 전투) 이때 에우메네스는 크라테로스의 명망 때문에, 부하들이 스스로를 배반하는 것을 두려워하여 크라테로스 앞에 그의 얼굴을 모르는 외국 병력을 배치했다. 그리고 그들에게 적들이 어떤 말도 할 틈을 주지 않고 즉시 돌격하라고 명령했다. 에우메네스의 계략은 성공했고, 크라테로스는 모자를 벗고 스스로 크라테로스라고 알렸지만, 낙마해서 아무도 눈치채지 못하고 말에 짓밟혀 죽었다.\n",
      "\n",
      "---\n",
      "\n",
      "[5] 원정의 첫 구간에 접어든 이후 두 번째 날, 고메스 페레스 다스마리냐스의 함대가 루손섬 해안을 벗어나 곧바로 마닐라로부터 24레구아 떨어진 카카섬(the island of Caca)에 도착하였다. 중국인들은 3일동안 갤리선 점령 계획을 세웠으며, 이날 밤 봉기를 일으켰다.\n",
      "\n",
      "동이 트기 전, 중국인들은 경비병과 자고 있던 스페인인들을 공격하여 대부분을 살해하였지만, 몇몇은 수영으로 혹은 갤리선의 부속선을 타고 도망쳤다. 소동을 듣자 총독 고메스 페레스 다스마리냐스는 무심결에 자신의 선실을 나섰다가, 문 밖에서 기다리고 있던 중국인들에게 살해당하였다. 총독의 비서 후안 데 쿠에야르(Juan de Cuellar)와 프란시스코회 신부 몬티야(Montilla)만이 각각 배 한 가운데 있는 자신의 선실에 있다가 살아남았다. 후에 중국인들은 이들을 해안가에 풀어주었다.\n"
     ]
    }
   ],
   "source": [
    "print(final_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_dir = \"/data/ephemeral/home/data/test_dataset/\"\n",
    "test_dataset = load_from_disk(test_set_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5028,  474,  461, 5015, 5032])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'context', 'question', 'id', 'answers', 'document_id', '__index_level_0__'],\n",
       "        num_rows: 3952\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['title', 'context', 'question', 'id', 'answers', 'document_id', '__index_level_0__'],\n",
       "        num_rows: 240\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [1:37:27<00:00,  9.75s/it]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "result_for_test = []\n",
    "\n",
    "for i in tqdm.tqdm(range(len(test_dataset['validation']['question']))):\n",
    "\n",
    "    # 질문과 id\n",
    "    test_q_query = test_dataset['validation'][i]['question']\n",
    "    test_q_id = test_dataset['validation'][i]['id']\n",
    "\n",
    "    # 골든리트리버 귀엽다\n",
    "    retrieved_nodes_test = retriever.retrieve(test_q_query)\n",
    "\n",
    "\n",
    "    # data for reranker\n",
    "    docs_for_rerank_test = [n.node.text for n in retrieved_nodes_test]\n",
    "    ids_for_rerank_test = [n.node.metadata['document_id'] for n in retrieved_nodes_test]\n",
    "\n",
    "\n",
    "\n",
    "    # rerank result\n",
    "    reranked_results_test = reranker.rerank(test_q_query, docs_for_rerank_test, ids_for_rerank_test, top_k=5)\n",
    "    result_for_test.append([test_q_id, (list(np.array(reranked_results_test[1])[:,0].astype(int)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mrc-1-000067'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [7,\n",
    "12,\n",
    "14,\n",
    "30,\n",
    "31,\n",
    "37,\n",
    "55,\n",
    "57,\n",
    "67,\n",
    "73,\n",
    "84,\n",
    "92,\n",
    "98,\n",
    "99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "result_for_train = []\n",
    "\n",
    "for i in tqdm.tqdm(range(len(dataset['validation']['question']))):\n",
    "\n",
    "    # 질문과 id\n",
    "    train_q_query = dataset['train'][i]['question']\n",
    "    train_q_id = dataset['train'][i]['id']\n",
    "\n",
    "    # 골든리트리버 귀엽다\n",
    "    retrieved_nodes_train = retriever.retrieve(train_q_query)\n",
    "\n",
    "\n",
    "    # data for reranker\n",
    "    docs_for_rerank_train = [n.node.text for n in retrieved_nodes_train]\n",
    "    ids_for_rerank_train = [n.node.metadata['document_id'] for n in retrieved_nodes_train]\n",
    "\n",
    "\n",
    "\n",
    "    # rerank result\n",
    "    reranked_results_train = reranker.rerank(train_q_query, docs_for_rerank_train, ids_for_rerank_train, top_k=20)\n",
    "    result = list(dict.fromkeys((list(map(int, ((list(np.array(reranked_results_train[1])[:,0].astype(int)))))))))[:5]\n",
    "\n",
    "    result_for_train.append([train_q_id, result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_json(data):\n",
    "    question_id = []\n",
    "    document_list = []\n",
    "\n",
    "    for q_id, doc_list in data:\n",
    "        question_id.append(q_id)\n",
    "        document_list.append(list(map(int, (doc_list))))\n",
    "    result_dict = {\n",
    "        \"question_id\": question_id,\n",
    "        \"document_id\": document_list\n",
    "    }\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_test = convert_to_json(result_for_test)\n",
    "json_test = convert_to_json(result_for_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './document_list/train_no_redundant.json'\n",
    "with open(file_path, 'w') as f:\n",
    "    json.dump(json_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './document_list/train_no_redundant.json'\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    k = json.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([43992, 56655, 43991, 39931, 54108], [43991, 39931, 43586, 54108, 6467])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k['document_id'][77],k2['document_id'][77]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.04"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3952*0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 2547/3952 [00:00<00:00, 8365.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "63\n",
      "77\n",
      "227\n",
      "282\n",
      "305\n",
      "555\n",
      "562\n",
      "635\n",
      "975\n",
      "1014\n",
      "1062\n",
      "1095\n",
      "1195\n",
      "1264\n",
      "1310\n",
      "1325\n",
      "1380\n",
      "1412\n",
      "1420\n",
      "1463\n",
      "1564\n",
      "1645\n",
      "1657\n",
      "1708\n",
      "2125\n",
      "2391\n",
      "2537\n",
      "2578\n",
      "2619\n",
      "2675\n",
      "2699\n",
      "2788\n",
      "2807\n",
      "2835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3952/3952 [00:00<00:00, 8278.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2863\n",
      "2968\n",
      "3042\n",
      "3099\n",
      "3282\n",
      "3370\n",
      "3373\n",
      "3388\n",
      "3543\n",
      "3746\n",
      "3886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 정답확인\n",
    "import tqdm\n",
    "j  =  0\n",
    "j_n = 0\n",
    "for i in tqdm.tqdm(range(len(dataset['train']['question']))):\n",
    "    doc = k['document_id'][i]\n",
    "    doc_2 = k2['document_id'][i]\n",
    "    answer_doc = dataset['train'][i]['document_id']\n",
    "    if answer_doc in doc:\n",
    "        j += 1\n",
    "        if answer_doc not in doc_2:\n",
    "            print(i)\n",
    "        \n",
    "    else:\n",
    "        j_n +=1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3952/3952 [00:00<00:00, 599186.29it/s]\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "for i in tqdm.tqdm(range(len(dataset['train']['question']))):\n",
    "    doc = k['document_id'][i]\n",
    "    has_duplicate = len(doc) != len(set(doc))\n",
    "    if has_duplicate:\n",
    "        j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j/3952"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mcr-uv)",
   "language": "python",
   "name": "mcr-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
