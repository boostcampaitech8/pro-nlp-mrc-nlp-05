"""
Prompt Optimizer: Critic + Optimizer ì—­í• 
1. Critic: ì˜¤ë‹µ ë¶„ì„ ë° í”¼ë“œë°± ìƒì„±
2. Optimizer: í”¼ë“œë°± ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ì¬ì‘ì„±
"""
import random
import re
from typing import List, Dict
from omegaconf import DictConfig

class PromptOptimizer:
    """í”„ë¡¬í”„íŠ¸ ìµœì í™” ì—”ì§„"""
    
    def __init__(
        self,
        qa_engine,
        llm_engine,
        sample_ratio: float = 0.2,
        max_rules: int = 7,
        evaluation_principles: List[str] = None
    ):
        """
        Args:
            qa_engine: QA_Engine ì¸ìŠ¤í„´ìŠ¤
            llm_engine: LLM ì—”ì§„ (í”¼ë“œë°±/ìµœì í™”ìš©)
            sample_ratio: ì˜¤ë‹µ ìƒ˜í”Œë§ ë¹„ìœ¨
            max_rules: ìµœëŒ€ ê·œì¹™ ê°œìˆ˜
            evaluation_principles: í‰ê°€ ê¸°ì¤€ (6ê°€ì§€ ì›ì¹™)
        """
        self.model = qa_engine
        self.llm = llm_engine
        self.sample_ratio = sample_ratio
        self.max_rules = max_rules
        self.principles = evaluation_principles or self._default_principles()
    
    def _default_principles(self) -> List[str]:
        """ê¸°ë³¸ í‰ê°€ ì›ì¹™"""
        return [
            "ì›ì¹™ 1. ì§ˆë¬¸ì´ ë¬»ëŠ” ëŒ€ìƒë§Œ ì¶”ì¶œ",
            "ì›ì¹™ 2. ë™ì–´ë°˜ë³µ ê¸ˆì§€",
            "ì›ì¹™ 3. íŠ¹ìˆ˜ë¬¸ì/ê¸°í˜¸ ì œê±°",
            "ì›ì¹™ 4. ìˆ«ì ì •í™•ì„±",
            "ì›ì¹™ 5. ê³ ìœ ëª…ì‚¬ ì •í™•ì„±",
            "ì›ì¹™ 6. ì¡°ì‚¬ ì œê±°"
        ]
    
    def _sample_errors(self, errors: List[Dict]) -> List[Dict]:
        """ì˜¤ë‹µ ìƒ˜í”Œë§ (ì¼ë°˜í™”ë¥¼ ìœ„í•´)"""
        sample_size = int(len(errors) * self.sample_ratio)
        sample_size = max(1, min(sample_size, len(errors)))
        return random.sample(errors, sample_size)
    
    def generate_feedback_batch(self, errors: List[Dict]) -> str:
        """
        Critic: ë°°ì¹˜ í”¼ë“œë°± ìƒì„±
        
        Args:
            errors: ì˜¤ë‹µ ì¼€ì´ìŠ¤ ë¦¬ìŠ¤íŠ¸
                [{
                    'question': str,
                    'context': str,
                    'pred': str,
                    'gt': str (or list)
                }, ...]
        
        Returns:
            ì¼ë°˜í™”ëœ í”¼ë“œë°± í…ìŠ¤íŠ¸
        """
        if not errors:
            return ""
        
        sampled = self._sample_errors(errors)
        print(f"   â†’ Sampled {len(sampled)}/{len(errors)} errors for feedback")
        
        # ì¼€ì´ìŠ¤ë³„ ìƒì„¸ ì •ë³´ êµ¬ì„±
        cases_text = ""
        for i, e in enumerate(sampled):
            gt_text = e['gt'] if isinstance(e['gt'], str) else e['gt'][0]
            
            # í• ë£¨ì‹œë„¤ì´ì…˜ ì²´í¬
            norm_ctx = e['context'].replace(" ", "").replace("\n", "")
            norm_pred = e['pred'].replace(" ", "").replace("\n", "")
            is_hallucination = norm_pred not in norm_ctx
            
            cases_text += f"""
[Case {i+1}]
- ì§ˆë¬¸: {e['question']}
- ì •ë‹µ: {gt_text}
- ì˜ˆì¸¡: {e['pred']}
- í™˜ê° ì—¬ë¶€: {"ì˜ˆ" if is_hallucination else "ì•„ë‹ˆì˜¤"}
"""
        
        # Critic í”„ë¡¬í”„íŠ¸
        critique_prompt = f"""ë‹¹ì‹ ì€ QA ì‹œìŠ¤í…œì˜ ì˜¤ë¥˜ë¥¼ ë¶„ì„í•˜ëŠ” ì–¸ì–´í•™ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì œê³µëœ 'ëª¨ë¸ì´ í‹€ë¦° ì¼€ì´ìŠ¤'ë¥¼ ë¶„ì„í•˜ì—¬, ì•„ë˜ [í‰ê°€ ê¸°ì¤€]ì— ì˜ê±°í•´ ì˜¤ë¥˜ ì›ì¸ì„ ì§„ë‹¨í•˜ê³  ìˆ˜ì • ì§€ì¹¨ì„ ë‚´ë¦¬ì‹­ì‹œì˜¤.

[í‰ê°€ ê¸°ì¤€]

{self.principles}

[í‰ê°€ ê¸°ì¤€ ë]

ë‹¤ìŒì€ ëª¨ë¸ì´ í‹€ë¦° ì¼€ì´ìŠ¤ë“¤ì…ë‹ˆë‹¤:
###
{cases_text}
###

**ìˆ˜í–‰ ê³¼ì œ:**
ìœ„ ì¼€ì´ìŠ¤ë“¤ì„ ë¶„ì„í•˜ì—¬ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.

**ì¶œë ¥ í˜•ì‹ (ë°˜ë“œì‹œ ì¤€ìˆ˜):**
ê° ì¼€ì´ìŠ¤ì— ëŒ€í•´ ì•„ë˜ í¬ë§·ì„ ì—„ê²©íˆ ë”°ë¥´ì‹­ì‹œì˜¤.

[Case N]
- ì°¨ì´: [ëª¨ë¸ì˜ ì˜¤ë‹µ] vs [ì •ë‹µ] ê°„ì˜ í…ìŠ¤íŠ¸ ì°¨ì´ ë¶„ì„
- ì›ì¸: **[ìœ„ë°˜ ì›ì¹™ ë²ˆí˜¸]**ë¥¼ ë¨¼ì € ì“°ê³ , í•´ë‹¹ ì›ì¹™ì— ìœ„ë°°ë˜ëŠ” ì´ìœ ë¥¼ ì„¤ëª…
- ì§€ì‹œ: ì •ë‹µì„ ë„ì¶œí•˜ê¸° ìœ„í•´ ëª¨ë¸ì´ ìˆ˜ì •í•´ì•¼ í•  êµ¬ì²´ì ì¸ í–‰ë™

---

**ë§ˆì§€ë§‰ ê³µí†µ íŒ¨í„´ ìš”ì•½:**
ìœ„ ì¼€ì´ìŠ¤ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ, ê°€ì¥ ë¹ˆë²ˆí•˜ê²Œ ë¬´ì‹œëœ ì›ì¹™ê³¼ í•´ê²°ì±… 3ê°€ì§€ë¥¼ ë„ì¶œí•˜ì‹­ì‹œì˜¤.
1. [ìœ„ë°˜ ì›ì¹™/ë¬¸ì œì ] -> [í•´ê²°ì„ ìœ„í•œ ì§€ì‹œì‚¬í•­]
2. [ìœ„ë°˜ ì›ì¹™/ë¬¸ì œì ] -> [í•´ê²°ì„ ìœ„í•œ ì§€ì‹œì‚¬í•­]
3. [ìœ„ë°˜ ì›ì¹™/ë¬¸ì œì ] -> [í•´ê²°ì„ ìœ„í•œ ì§€ì‹œì‚¬í•­]
"""
        
        response = self.llm.create_chat_completion(
            messages=[{"role": "user", "content": critique_prompt}],
            temperature=0.7
        )
        
        return response['choices'][0]['message']['content'].strip()
    
    def step(self, error_batch: List[Dict]):
        """
        Optimizer: í”¼ë“œë°± ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ì—…ë°ì´íŠ¸
        
        Args:
            error_batch: ì˜¤ë‹µ ì¼€ì´ìŠ¤ ë°°ì¹˜
        """
        if not error_batch:
            return
        
        print(f"\n[Optimizer] Processing {len(error_batch)} errors...")
        
        # 1ë‹¨ê³„: Critic - ë°°ì¹˜ í”¼ë“œë°± ìƒì„±
        summarized_feedback = self.generate_feedback_batch(error_batch)
        print(f"   â†’ Feedback generated\n")
        
        # 2ë‹¨ê³„: Optimizer - í”„ë¡¬í”„íŠ¸ ì¬ì‘ì„±
        current_prompt = self.model.system_prompt
        
        optimization_prompt = f"""ë‹¹ì‹ ì€ NLP ì •ë³´ ì¶”ì¶œ(Information Extraction) ìµœì í™” ì „ë¬¸ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ì…ë‹ˆë‹¤.
ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì£¼ì–´ì§„ [í”¼ë“œë°±]ì„ ë¶„ì„í•˜ì—¬, EM(Exact Match) ì ìˆ˜ë¥¼ 100ì ìœ¼ë¡œ ë§Œë“¤ê¸° ìœ„í•´ [í˜„ì¬ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸]ë¥¼ ì¬ì‘ì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

[í˜„ì¬ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸]
{current_prompt}

[ê²€ì¦ ë°ì´í„°ì—ì„œì˜ í”¼ë“œë°± (Critical Feedback)]
{summarized_feedback}

[í”„ë¡¬í”„íŠ¸ ì¬ì‘ì„± ê°€ì´ë“œë¼ì¸]

1. ê·œì¹™ì˜ ì¶”ìƒí™” ë° ì¼ë°˜í™” (Rule Abstraction):
   - í”¼ë“œë°±ì˜ ê°œë³„ ì‚¬ë¡€ì— ì§‘ì°©í•˜ì§€ ë§ê³ , **ì˜¤ë¥˜ì˜ ì›ì¸(Error Type)**ì„ ë¶„ì„í•˜ì—¬ ì¼ë°˜í™”ëœ ê·œì¹™ì„ ë„ì¶œí•˜ì‹­ì‹œì˜¤.
   - ìœ ì‚¬í•œ ì˜¤ë¥˜ë“¤ì€ í•˜ë‚˜ì˜ ê°•ë ¥í•œ ìƒìœ„ ê·œì¹™ìœ¼ë¡œ í†µí•©í•˜ì‹­ì‹œì˜¤.
   - ì •ë‹µ ì¶”ì¶œ ì›ì¹™ì€ **{self.max_rules}ê°œ ì´í•˜**ë¡œ ì œí•œ
   - íŠ¹ì • ë‹¨ì–´ ë‚˜ì—´ ê¸ˆì§€, ëª¨ë“  ë„ë©”ì¸ì— ì ìš© ê°€ëŠ¥í•˜ê²Œ ì‘ì„±

2. Few-Shot ì˜ˆì‹œ (Crucial):
   - í”¼ë“œë°±ì—ì„œ ì§€ì ëœ ì˜¤ë¥˜ ì¼€ì´ìŠ¤ë¥¼ í•´ê²°í•  ìˆ˜ ìˆëŠ” ì¼ë°˜í™”ëœ **ìƒˆë¡œìš´ Few-Shot ì˜ˆì‹œ(Input-Output ìŒ)** ìµœëŒ€ 2ê°œë¥¼ í¬í•¨í•˜ì‹­ì‹œì˜¤.

3. ì¶œë ¥ í¬ë§· ì—„ê²©í™”:
   - ëª¨ë¸ì´ ì¶”ë¡  ê³¼ì •(Evidence)ê³¼ ê²°ê³¼(Answer)ë¥¼ ë¶„ë¦¬í•˜ë„ë¡ ì•„ë˜ JSON í¬ë§·ì„ ê°•ì œí•˜ì‹­ì‹œì˜¤.

ì¶œë ¥ì—ëŠ” ì„¤ëª…, ìš”ì•½, í‘œ, ì œëª©, ë§ˆí¬ë‹¤ìš´ì„ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
ì˜¤ì§ "ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë³¸ë¬¸ í…ìŠ¤íŠ¸"ë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.

[ì¶œë ¥ í˜•ì‹]
Evidence: "ì •ë‹µì´_í¬í•¨ëœ_ë¬¸ì¥"
{{"extracted_answer": "í•µì‹¬_ì •ë‹µ"}}
"""
        
        response = self.llm.create_chat_completion(
            messages=[{"role": "user", "content": optimization_prompt}],
            temperature=0.5
        )
        
        new_prompt = response['choices'][0]['message']['content'].strip()
        
        # í”„ë¡¬í”„íŠ¸ ê²€ì¦
        print(f"ğŸ” Generated prompt (len={len(new_prompt)})")
        has_format = any(x in new_prompt.lower() for x in ["extracted_answer", "evidence"])
        
        if len(new_prompt) > 100 and has_format:
            self.model.update_prompt(new_prompt)
            print("âœ… Prompt updated!")
        else:
            print(f"âš ï¸ Validation failed. len={len(new_prompt)}, has_format={has_format}")
    
    def _format_principles(self) -> str:
        if isinstance(self.principles, DictConfig):
            # YAML êµ¬ì¡° íŒŒì‹±í•˜ì—¬ í…ìŠ¤íŠ¸ ìƒì„±
            principles_text = ""
            for idx, (key, principle) in enumerate(self.principles.items(), 1):
                principles_text += f"ì›ì¹™ {idx}.\n{principle.description}\n\n"
                # ì˜ˆì‹œë“¤ ì¶”ê°€...
            return principles_text
