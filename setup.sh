#!/bin/bash
set -e

echo "NLP í…ŒìŠ¤íŠ¸ í™˜ê²½ êµ¬ì¶•ì„ ì‹œì‘í•©ë‹ˆë‹¤ (All in /data/ephemeral)..."

# ==========================================
# 0. í•µì‹¬: ëª¨ë“  ì €ì¥ì†Œë¥¼ /data/ephemeralë¡œ ê°•ì œ ì§€ì •
# ==========================================
echo "[0/6] ì‘ì—… ê³µê°„ ë° ìºì‹œ ê²½ë¡œ ì„¤ì •..."

# ë©”ì¸ ì‘ì—… ë””ë ‰í† ë¦¬ ìƒì„±
WORK_DIR="/data/ephemeral/nlp_workspace"
mkdir -p "$WORK_DIR"
chmod 777 "$WORK_DIR"

# ì„ì‹œ ë””ë ‰í† ë¦¬ë„ ephemeralë¡œ!
export TMPDIR="/data/ephemeral/tmp"
mkdir -p "$TMPDIR"
export TEMP="$TMPDIR"
export TMP="$TMPDIR"

# ìºì‹œ ë””ë ‰í† ë¦¬ ì„¤ì • (Root ìš©ëŸ‰ ë¶€ì¡± ë°©ì§€)
export XDG_CACHE_HOME="/data/ephemeral/.cache"
export PIP_CACHE_DIR="/data/ephemeral/.cache/pip"
export UV_CACHE_DIR="/data/ephemeral/.cache/uv"
export HF_HOME="/data/ephemeral/.cache/huggingface"

mkdir -p "$XDG_CACHE_HOME"
mkdir -p "$PIP_CACHE_DIR"
mkdir -p "$UV_CACHE_DIR"
mkdir -p "$HF_HOME"

# ì‘ì—… ê³µê°„ìœ¼ë¡œ ì´ë™ (ì´ì œë¶€í„° ëª¨ë“  íŒŒì¼ì€ ì—¬ê¸°ì— ìƒê¹€)
cd "$WORK_DIR"
echo "í˜„ì¬ ì‘ì—… ìœ„ì¹˜: $(pwd)"

# íƒ€ì„ì¡´ ì„¤ì •
echo "íƒ€ì„ì¡´ì„ Asia/Seoulë¡œ ì„¤ì •í•©ë‹ˆë‹¤..."
export DEBIAN_FRONTEND=noninteractive
export TZ=Asia/Seoul
ln -snf /usr/share/zoneinfo/$TZ /etc/localtime
echo $TZ | tee /etc/timezone

# ==========================================
# 1. ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
# ==========================================
echo "ğŸ“¦ [1/6] ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì—…ë°ì´íŠ¸ ë° ì„¤ì¹˜..."
apt-get update
apt-get install -y tzdata vim wget build-essential cmake

# ì„¤ì¹˜ í›„ ì •ë¦¬
apt-get clean
rm -rf /var/cache/apt/archives/*
sync
sleep 2

# ==========================================
# 2. CUDA ì„¤ì¹˜ (ì„¤ì¹˜ íŒŒì¼ ë° ê²½ë¡œ ëª¨ë‘ ephemeral)
# ==========================================
if [ ! -d "/data/ephemeral/cuda-12.2" ]; then
    echo " [2/6] CUDA 12.2 ì„¤ì¹˜ ì¤‘..."
    
    # ë‹¤ìš´ë¡œë“œ (ephemeralì— ë‹¤ìš´ë¨)
    wget https://developer.download.nvidia.com/compute/cuda/12.2.0/local_installers/cuda_12.2.0_535.54.03_linux.run
    chmod +x cuda_12.2.0_535.54.03_linux.run
    
    # ì„¤ì¹˜ (Toolkit ê²½ë¡œë¥¼ ephemeralë¡œ ì§€ì •)
    sh cuda_12.2.0_535.54.03_linux.run --silent --toolkit --toolkitpath=/data/ephemeral/cuda-12.2
    
    # ì‹¬ë³¼ë¦­ ë§í¬
    ln -sf /data/ephemeral/cuda-12.2 /usr/local/cuda
    
    # ì„¤ì¹˜ íŒŒì¼ ì‚­ì œ ë° ì •ë¦¬
    rm -f cuda_12.2.0_535.54.03_linux.run
    sync
    sleep 3
    echo "CUDA ì„¤ì¹˜ ì™„ë£Œ ë° ì •ë¦¬ë¨"
else
    echo "CUDAê°€ ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤."
fi

# ==========================================
# 3. í™˜ê²½ë³€ìˆ˜ ì„¤ì •
# ==========================================
echo "[3/6] í™˜ê²½ë³€ìˆ˜ ì„¤ì • ì¤‘..."

# ìºì‹œ ê²½ë¡œ ì˜êµ¬ ë“±ë¡
if ! grep -q "XDG_CACHE_HOME" ~/.bashrc; then
    cat >> ~/.bashrc << 'CACHE_EOF'
# Ephemeral ìºì‹œ ê²½ë¡œ
export TMPDIR="/data/ephemeral/tmp"
export TEMP="$TMPDIR"
export TMP="$TMPDIR"
export XDG_CACHE_HOME="/data/ephemeral/.cache"
export PIP_CACHE_DIR="/data/ephemeral/.cache/pip"
export UV_CACHE_DIR="/data/ephemeral/.cache/uv"
export HF_HOME="/data/ephemeral/.cache/huggingface"
CACHE_EOF
fi

# CUDA ê²½ë¡œ ì˜êµ¬ ë“±ë¡
if ! grep -q "CUDA_HOME" ~/.bashrc; then
    cat >> ~/.bashrc << 'CUDA_EOF'
# CUDA í™˜ê²½ë³€ìˆ˜
export PATH=/usr/local/cuda/bin:$PATH
export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH
export CUDA_HOME=/usr/local/cuda
export CUDACXX=/usr/local/cuda/bin/nvcc
CUDA_EOF
fi

# í˜„ì¬ ì„¸ì…˜ ì ìš©
export PATH=/usr/local/cuda/bin:$PATH
export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH
export CUDA_HOME=/usr/local/cuda
export CUDACXX=/usr/local/cuda/bin/nvcc

# ==========================================
# 4. uv ì„¤ì¹˜ ë° í”„ë¡œì íŠ¸ ì´ˆê¸°í™”
# ==========================================
echo "[4/6] Python 3.12 & uv ì´ˆê¸°í™”..."
pip install uv

# í˜„ì¬ í´ë”(/data/ephemeral/nlp_workspace)ì— ì´ˆê¸°í™”
uv init --python 3.12.1 . 
uv sync

sync
sleep 2

# ==========================================
# 5. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
# ==========================================
echo "[5/6] ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (GPU ê°€ì† í¬í•¨)..."
source .venv/bin/activate

# requirements.txtê°€ ì—†ìœ¼ë©´ ìƒì„±
if [ ! -f "requirements.txt" ]; then
    echo "requirements.txt íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤..."
    cat <<REQ_EOF > requirements.txt
llama-index
langchain
langchain-community
adalflow[ollama]
mlflow
llama-cpp-python[server]
unsloth
unsloth_zoo
transformers
datasets
sentence-transformers
jedi>=0.16
autogen
autogen-agentchat
autogen-ext[openai]
llama-index-llms-llama-cpp
llama-index-llms-openai
llama-index-llms-upstage
llama-index-embeddings-huggingface
llama-index-embeddings-upstage
llama-index-retrievers-bm25
llama-index-readers-wikipedia
llama-index-readers-file
llama-index-graph-stores-neo4j
llama-index-vector-stores-neo4jvector
ollama
neo4j
SPARQLWrapper
wikipedia
wikipedia-api
REQ_EOF
fi

CMAKE_ARGS="-DGGML_CUDA=on" uv pip install -r requirements.txt

# ì¤‘ê°„ ì •ë¦¬
sync
sleep 2

uv pip install unsloth unsloth_zoo --upgrade

# ìµœì¢… ì •ë¦¬
sync
sleep 2

# ==========================================
# 6. ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ì••ì¶• í•´ì œ
# ==========================================
echo " [6/6] ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ì••ì¶• í•´ì œ..."

# data.tar.gzê°€ ì—†ìœ¼ë©´ ë‹¤ìš´ë¡œë“œ
if [ ! -f "data.tar.gz" ]; then
    echo "ë°ì´í„° íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘..."
    wget https://aistages-api-public-prod.s3.amazonaws.com/app/Competitions/000270/data/data.tar.gz
else
    echo " data.tar.gz íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤."
fi

# data í´ë”ê°€ ì—†ìœ¼ë©´ ì••ì¶• í•´ì œ
if [ ! -d "data" ]; then
    echo "ì••ì¶• í•´ì œ ì¤‘..."
    tar -zxvf data.tar.gz
    echo " ì••ì¶• í•´ì œ ì™„ë£Œ"
else
    echo " data í´ë”ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ì••ì¶• í•´ì œë¥¼ ìŠ¤í‚µí•©ë‹ˆë‹¤."
fi

# ì •ë¦¬
sync

echo ""
echo " ëª¨ë“  ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!"
echo " ì„¤ì¹˜ ìœ„ì¹˜: /data/ephemeral/nlp_workspace"
echo " ë°ì´í„° ìœ„ì¹˜: /data/ephemeral/nlp_workspace/data"
echo " ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰:"
df -h | grep -E "Filesystem|/data|/$"
echo ""
echo " ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì´ë™ ë° í™œì„±í™”í•˜ì„¸ìš”:"
echo "   cd /data/ephemeral/nlp_workspace"
echo "   source .venv/bin/activate"